{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(filename='enhanced_subway_model_fast.pkl'):\n",
    "    \"\"\"í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    try:\n",
    "        model_data = joblib.load(filename)\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "        try:\n",
    "            model_data = joblib.load('../result/enhanced_subway_model_fast.pkl')\n",
    "            print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: ../result/enhanced_subway_model_fast.pkl\")\n",
    "            return model_data\n",
    "        except:\n",
    "            print(\"âŒ ëŒ€ì²´ ê²½ë¡œì—ì„œë„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInsights:\n",
    "    def __init__(self, model_data):\n",
    "        self.best_model = model_data['best_model']\n",
    "        self.feature_engineer = model_data['feature_engineer']\n",
    "        self.selected_features = model_data['selected_features']\n",
    "        self.results = model_data['results']\n",
    "        self.feature_importance = model_data['feature_importance']\n",
    "        # ì‹œê°í™”ìš© ë°ì´í„°\n",
    "        self.X_test = model_data['test_data']['X_test']\n",
    "        self.y_test = model_data['test_data']['y_test']\n",
    "        self.test_data = model_data['test_data']['test_data_full']\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"ê²°ê³¼ ì‹œê°í™” (ì›ë³¸ê³¼ ë™ì¼)\"\"\"\n",
    "        print(\"\\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('ê³ ë„í™”ëœ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1) ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "        model_names = list(self.results.keys())\n",
    "        mae_scores = [self.results[name]['mae'] for name in model_names]\n",
    "        r2_scores = [self.results[name]['r2'] for name in model_names]\n",
    "        \n",
    "        axes[0, 0].bar(model_names, mae_scores, color='skyblue', alpha=0.7)\n",
    "        axes[0, 0].set_title('ëª¨ë¸ë³„ MAE ë¹„êµ')\n",
    "        axes[0, 0].set_ylabel('Mean Absolute Error')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        axes[0, 1].bar(model_names, r2_scores, color='lightgreen', alpha=0.7)\n",
    "        axes[0, 1].set_title('ëª¨ë¸ë³„ RÂ² ë¹„êµ')\n",
    "        axes[0, 1].set_ylabel('RÂ² Score')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 2) íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)\n",
    "        if self.feature_importance is not None:\n",
    "            top_features = self.feature_importance.head(15)\n",
    "            axes[0, 2].barh(top_features['feature'][::-1], top_features['importance'][::-1])\n",
    "            axes[0, 2].set_title('íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)')\n",
    "            axes[0, 2].set_xlabel('ì¤‘ìš”ë„')\n",
    "        \n",
    "        # 3) ì˜ˆì¸¡ vs ì‹¤ì œ (ìµœê³  ëª¨ë¸)\n",
    "        if self.best_model is not None:\n",
    "            y_pred = self.best_model.predict(self.X_test)\n",
    "            \n",
    "            # ìƒ˜í”Œë§ (ì‹œê°í™” ìµœì í™”)\n",
    "            if len(self.y_test) > 10000:\n",
    "                sample_idx = np.random.choice(len(self.y_test), 10000, replace=False)\n",
    "                y_test_sample = self.y_test.iloc[sample_idx]\n",
    "                y_pred_sample = y_pred[sample_idx]\n",
    "            else:\n",
    "                y_test_sample = self.y_test\n",
    "                y_pred_sample = y_pred\n",
    "            \n",
    "            axes[1, 0].scatter(y_test_sample, y_pred_sample, alpha=0.5, s=1)\n",
    "            axes[1, 0].plot([y_test_sample.min(), y_test_sample.max()], \n",
    "                           [y_test_sample.min(), y_test_sample.max()], 'r--', lw=2)\n",
    "            axes[1, 0].set_xlabel('ì‹¤ì œ í˜¼ì¡ë„')\n",
    "            axes[1, 0].set_ylabel('ì˜ˆì¸¡ í˜¼ì¡ë„')\n",
    "            axes[1, 0].set_title('ì˜ˆì¸¡ vs ì‹¤ì œ (ìµœê³  ëª¨ë¸)')\n",
    "            \n",
    "            # 4) ì”ì°¨ ë¶„í¬\n",
    "            residuals = y_test_sample - y_pred_sample\n",
    "            axes[1, 1].hist(residuals, bins=50, alpha=0.7, color='orange')\n",
    "            axes[1, 1].set_xlabel('ì”ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)')\n",
    "            axes[1, 1].set_ylabel('ë¹ˆë„')\n",
    "            axes[1, 1].set_title('ì”ì°¨ ë¶„í¬')\n",
    "            axes[1, 1].axvline(0, color='red', linestyle='--')\n",
    "            \n",
    "            # 5) ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥\n",
    "            test_data_with_pred = self.test_data.copy()\n",
    "            test_data_with_pred['predictions'] = self.best_model.predict(self.X_test)\n",
    "            test_data_with_pred['residuals'] = abs(test_data_with_pred['congestion'] - test_data_with_pred['predictions'])\n",
    "            \n",
    "            hourly_mae = test_data_with_pred.groupby('hour')['residuals'].mean()\n",
    "            axes[1, 2].plot(hourly_mae.index, hourly_mae.values, marker='o', linewidth=2)\n",
    "            axes[1, 2].set_title('ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ì˜¤ì°¨ (MAE)')\n",
    "            axes[1, 2].set_xlabel('ì‹œê°„')\n",
    "            axes[1, 2].set_ylabel('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨')\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "            axes[1, 2].set_xticks(range(0, 24, 2))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        try:\n",
    "            plt.savefig('../result/enhanced_model_results.png', dpi=300, bbox_inches='tight')\n",
    "        except:\n",
    "            plt.savefig('enhanced_model_results.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        \"\"\"ê°œì„ ëœ ëª¨ë¸ ì¸ì‚¬ì´íŠ¸ (ì›ë³¸ê³¼ ë™ì¼)\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸš€ ê³ ë„í™”ëœ ëª¨ë¸ ì¸ì‚¬ì´íŠ¸\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])\n",
    "        best_result = self.results[best_model_name]\n",
    "        \n",
    "        print(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}\")\n",
    "        print(f\"  ğŸ“Š MAE: {best_result['mae']:.3f}\")\n",
    "        print(f\"  ğŸ“Š RMSE: {best_result['rmse']:.3f}\")\n",
    "        print(f\"  ğŸ“Š RÂ²: {best_result['r2']:.3f}\")\n",
    "        \n",
    "        # ì„±ëŠ¥ ê°œì„  ë¶„ì„\n",
    "        print(f\"\\nğŸ“ˆ ëª¨ë¸ ê°œì„  íš¨ê³¼:\")\n",
    "        if best_result['r2'] > 0.8:\n",
    "            print(\"  âœ… ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì„±ëŠ¥ ë‹¬ì„±\")\n",
    "        elif best_result['r2'] > 0.6:\n",
    "            print(\"  â­ ì–‘í˜¸í•œ ì˜ˆì¸¡ ì„±ëŠ¥\")\n",
    "        else:\n",
    "            print(\"  ğŸ”§ ì¶”ê°€ ê°œì„  í•„ìš”\")\n",
    "        \n",
    "        # íŠ¹ì„± ì¤‘ìš”ë„ ì¸ì‚¬ì´íŠ¸\n",
    "        if self.feature_importance is not None:\n",
    "            print(f\"\\nğŸ¯ í•µì‹¬ ì˜ˆì¸¡ ìš”ì¸ (ìƒìœ„ 5ê°œ):\")\n",
    "            for i, (_, row) in enumerate(self.feature_importance.head(5).iterrows()):\n",
    "                print(f\"  {i+1}. {row['feature']}: {row['importance']:.3f}\")\n",
    "            \n",
    "            # íŠ¹ì„± ìœ í˜•ë³„ ë¶„ì„\n",
    "            importance_by_type = {}\n",
    "            for _, row in self.feature_importance.iterrows():\n",
    "                feature = row['feature']\n",
    "                if any(x in feature for x in ['extreme_', 'heavy_', 'strong_']):\n",
    "                    importance_by_type['ê·¹í•œê¸°ìƒ'] = importance_by_type.get('ê·¹í•œê¸°ìƒ', 0) + row['importance']\n",
    "                elif any(x in feature for x in ['interaction', '_x_', 'temp_humidity']):\n",
    "                    importance_by_type['ìƒí˜¸ì‘ìš©'] = importance_by_type.get('ìƒí˜¸ì‘ìš©', 0) + row['importance']\n",
    "                elif any(x in feature for x in ['lag_', '_ma_', 'shift']):\n",
    "                    importance_by_type['ì‹œì°¨íŠ¹ì„±'] = importance_by_type.get('ì‹œì°¨íŠ¹ì„±', 0) + row['importance']\n",
    "                elif any(x in feature for x in ['hour', 'day', 'time_period', 'season']):\n",
    "                    importance_by_type['ì‹œê°„íŠ¹ì„±'] = importance_by_type.get('ì‹œê°„íŠ¹ì„±', 0) + row['importance']\n",
    "                else:\n",
    "                    importance_by_type['ê¸°ë³¸íŠ¹ì„±'] = importance_by_type.get('ê¸°ë³¸íŠ¹ì„±', 0) + row['importance']\n",
    "            \n",
    "            print(f\"\\nğŸ“Š íŠ¹ì„± ìœ í˜•ë³„ ì¤‘ìš”ë„:\")\n",
    "            for feature_type, importance in sorted(importance_by_type.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {feature_type}: {importance:.3f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ ì‹¤ë¬´ í™œìš© ì œì•ˆ:\")\n",
    "        print(\"  ğŸ¯ ê·¹í•œ ê¸°ìƒ ì¡°ê±´ì—ì„œì˜ í˜¼ì¡ë„ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ\")\n",
    "        print(\"  ğŸ¯ ì„¸ë¶„í™”ëœ ì‹œê°„ëŒ€ë³„ ë§ì¶¤í˜• ìš´ì˜ ì „ëµ ìˆ˜ë¦½\")\n",
    "        print(\"  ğŸ¯ ê¸°ìƒ-ì‹œê°„ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•œ ë™ì  ë°°ì°¨ ê³„íš\")\n",
    "        print(\"  ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ í•µì‹¬ ìš”ì¸ ëª¨ë‹ˆí„°ë§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model_data = load_trained_model()\n",
    "\n",
    "if model_data is not None:\n",
    "    # ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ê°ì²´ ìƒì„±\n",
    "    insights = ModelInsights(model_data)\n",
    "    print(\"âœ… ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_data is not None:\n",
    "    try:\n",
    "        insights.plot_results()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì‹œê°í™” ì˜¤ë¥˜: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights.generate_insights() if insights else print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
