#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Subway Congestion Prediction Model
ê³ ë„í™”ëœ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ ëª¨ë¸

ê°œì„ ì‚¬í•­:
1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)
2. ê·¹í•œ ê¸°ìƒ ìƒíƒœ ì´ì§„ ë³€ìˆ˜
3. ì„¸ë¶„í™”ëœ ì‹œê°„ëŒ€/ê³„ì ˆ ë²”ì£¼í˜• ë³€ìˆ˜
4. ìƒí˜¸ì‘ìš© í•­ ì¶”ê°€
5. íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.feature_selection import SelectFromModel, RFE
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
import xgboost as xgb
import lightgbm as lgb
import optuna
import warnings
import os
import joblib
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class EnhancedFeatureEngineering:
    """ê³ ë„í™”ëœ íŠ¹ì„± ê³µí•™"""
    
    def __init__(self):
        self.scalers = {}
        self.encoders = {}
        self.selected_features = None
        
    def create_extreme_weather_features(self, df):
        """ê·¹í•œ ê¸°ìƒ ìƒíƒœ ì´ì§„ ë³€ìˆ˜ ìƒì„±"""
        print("ğŸŒªï¸ ê·¹í•œ ê¸°ìƒ ìƒíƒœ ë³€ìˆ˜ ìƒì„± ì¤‘...")
        
        # ì˜¨ë„ ê¸°ë°˜ ê·¹í•œ ìƒíƒœ
        if 'ta' in df.columns:
            temp_q05 = df['ta'].quantile(0.05)  # í•œíŒŒ
            temp_q95 = df['ta'].quantile(0.95)  # í­ì—¼
            
            df['extreme_cold'] = (df['ta'] <= temp_q05).astype(int)
            df['extreme_heat'] = (df['ta'] >= temp_q95).astype(int)
            df['moderate_temp'] = ((df['ta'] > temp_q05) & (df['ta'] < temp_q95)).astype(int)
            
            print(f"  í•œíŒŒ ê¸°ì¤€: â‰¤{temp_q05:.1f}Â°C ({df['extreme_cold'].sum():,}ê°œ)")
            print(f"  í­ì—¼ ê¸°ì¤€: â‰¥{temp_q95:.1f}Â°C ({df['extreme_heat'].sum():,}ê°œ)")
        
        # ê°•ìˆ˜ ê¸°ë°˜ ê·¹í•œ ìƒíƒœ
        if 'rn_hr1' in df.columns:
            df['no_rain'] = (df['rn_hr1'] == 0).astype(int)
            df['light_rain'] = ((df['rn_hr1'] > 0) & (df['rn_hr1'] <= 2)).astype(int)
            df['heavy_rain'] = (df['rn_hr1'] > 10).astype(int)
            df['extreme_rain'] = (df['rn_hr1'] > 30).astype(int)
            
            print(f"  í­ìš° ê¸°ì¤€: >10mm ({df['heavy_rain'].sum():,}ê°œ)")
            print(f"  ê·¹í•œ ê°•ìˆ˜: >30mm ({df['extreme_rain'].sum():,}ê°œ)")
        
        # í’ì† ê¸°ë°˜ ê·¹í•œ ìƒíƒœ
        if 'ws' in df.columns:
            wind_q90 = df['ws'].quantile(0.90)
            wind_q95 = df['ws'].quantile(0.95)
            
            df['calm_wind'] = (df['ws'] <= 1.0).astype(int)
            df['strong_wind'] = (df['ws'] >= wind_q90).astype(int)
            df['extreme_wind'] = (df['ws'] >= wind_q95).astype(int)
            
            print(f"  ê°•í’ ê¸°ì¤€: â‰¥{wind_q90:.1f}m/s ({df['strong_wind'].sum():,}ê°œ)")
            print(f"  ê·¹í•œ í’ì†: â‰¥{wind_q95:.1f}m/s ({df['extreme_wind'].sum():,}ê°œ)")
        
        # ìŠµë„ ê¸°ë°˜ ê·¹í•œ ìƒíƒœ
        if 'hm' in df.columns:
            humidity_q05 = df['hm'].quantile(0.05)
            humidity_q95 = df['hm'].quantile(0.95)
            
            df['extreme_dry'] = (df['hm'] <= humidity_q05).astype(int)
            df['extreme_humid'] = (df['hm'] >= humidity_q95).astype(int)
            
            print(f"  ê·¹ê±´ì¡°: â‰¤{humidity_q05:.1f}% ({df['extreme_dry'].sum():,}ê°œ)")
            print(f"  ê·¹ìŠµí•¨: â‰¥{humidity_q95:.1f}% ({df['extreme_humid'].sum():,}ê°œ)")
        
        # ë³µí•© ê·¹í•œ ìƒíƒœ
        df['extreme_weather_any'] = (
            df.get('extreme_cold', 0) | df.get('extreme_heat', 0) |
            df.get('heavy_rain', 0) | df.get('extreme_wind', 0) |
            df.get('extreme_dry', 0) | df.get('extreme_humid', 0)
        ).astype(int)
        
        print(f"  ì „ì²´ ê·¹í•œ ê¸°ìƒ: {df['extreme_weather_any'].sum():,}ê°œ ({df['extreme_weather_any'].mean()*100:.1f}%)")
        
        return df
    
    def create_detailed_time_features(self, df):
        """ì„¸ë¶„í™”ëœ ì‹œê°„ëŒ€/ê³„ì ˆ ë²”ì£¼í˜• ë³€ìˆ˜"""
        print("â° ì„¸ë¶„í™”ëœ ì‹œê°„ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì‹œê°„ ê´€ë ¨ ê¸°ë³¸ íŠ¹ì„±
        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')
        df['hour'] = df['datetime'].dt.hour
        df['dayofweek'] = df['datetime'].dt.dayofweek
        df['month'] = df['datetime'].dt.month
        df['day'] = df['datetime'].dt.day
        df['week_of_year'] = df['datetime'].dt.isocalendar().week
        
        # ì„¸ë¶„í™”ëœ ì¶œí‡´ê·¼ ì‹œê°„ëŒ€
        def get_detailed_time_period(hour):
            if hour in [6, 7]:
                return 'early_morning_rush'
            elif hour in [8, 9]:
                return 'morning_rush_peak'
            elif hour == 10:
                return 'morning_rush_end'
            elif hour in [11, 12, 13, 14]:
                return 'daytime'
            elif hour in [15, 16]:
                return 'afternoon_start'
            elif hour in [17, 18]:
                return 'evening_rush_start'
            elif hour in [19, 20]:
                return 'evening_rush_peak'
            elif hour == 21:
                return 'evening_rush_end'
            elif hour in [22, 23]:
                return 'night'
            else:  # 0-5ì‹œ
                return 'late_night'
        
        df['time_period'] = df['hour'].apply(get_detailed_time_period)
        
        # ì„¸ë¶„í™”ëœ ê³„ì ˆ
        def get_detailed_season(month):
            if month in [12, 1, 2]:
                return 'winter'
            elif month in [3, 4]:
                return 'spring_early'
            elif month == 5:
                return 'spring_late'
            elif month in [6, 7]:
                return 'summer_early'
            elif month == 8:
                return 'summer_peak'
            elif month in [9, 10]:
                return 'autumn_early'
            else:  # 11ì›”
                return 'autumn_late'
        
        df['detailed_season'] = df['month'].apply(get_detailed_season)
        
        # ì£¼ë§/í‰ì¼ ì„¸ë¶„í™”
        df['day_type'] = df['dayofweek'].apply(
            lambda x: 'weekend' if x >= 5 else 'weekday'
        )
        
        # ì›”ìš”ì¼/ê¸ˆìš”ì¼ íš¨ê³¼
        df['is_monday'] = (df['dayofweek'] == 0).astype(int)
        df['is_friday'] = (df['dayofweek'] == 4).astype(int)
        
        # ìˆœí™˜ì  ì‹œê°„ íŠ¹ì„± (ê¸°ì¡´ + ì¶”ê°€)
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['week_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)
        df['week_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)
        
        print(f"  ì„¸ë¶„í™”ëœ ì‹œê°„ëŒ€: {df['time_period'].nunique()}ê°œ ì¹´í…Œê³ ë¦¬")
        print(f"  ì„¸ë¶„í™”ëœ ê³„ì ˆ: {df['detailed_season'].nunique()}ê°œ ì¹´í…Œê³ ë¦¬")
        
        return df
    
    def create_interaction_features(self, df):
        """ìƒí˜¸ì‘ìš© í•­ ìƒì„±"""
        print("ğŸ”— ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê¸°ìƒ ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš©
        if 'ta' in df.columns and 'hm' in df.columns:
            # ì²´ê°ì˜¨ë„ (ì˜¨ë„ Ã— ìŠµë„)
            df['apparent_temp'] = df['ta'] * (1 + df['hm'] / 100)
            df['temp_humidity_interaction'] = df['ta'] * df['hm']
            print("  ì˜¨ë„ Ã— ìŠµë„ ìƒí˜¸ì‘ìš© ìƒì„±")
        
        if 'ta' in df.columns and 'ws' in df.columns:
            # í’ì†ì— ì˜í•œ ì²´ê°ì˜¨ë„
            df['wind_chill'] = df['ta'] - df['ws'] * 2
            df['temp_wind_interaction'] = df['ta'] * df['ws']
            print("  ì˜¨ë„ Ã— í’ì† ìƒí˜¸ì‘ìš© ìƒì„±")
        
        if 'rn_hr1' in df.columns and 'ws' in df.columns:
            # ë¹„ë°”ëŒ íš¨ê³¼
            df['rain_wind_interaction'] = df['rn_hr1'] * df['ws']
            print("  ê°•ìˆ˜ Ã— í’ì† ìƒí˜¸ì‘ìš© ìƒì„±")
        
        if 'rn_hr1' in df.columns and 'hm' in df.columns:
            # ìŠµë„-ê°•ìˆ˜ ìƒí˜¸ì‘ìš©
            df['rain_humidity_interaction'] = df['rn_hr1'] * df['hm']
            print("  ê°•ìˆ˜ Ã— ìŠµë„ ìƒí˜¸ì‘ìš© ìƒì„±")
        
        # ì‹œê°„-ê¸°ìƒ ìƒí˜¸ì‘ìš©
        if 'ta' in df.columns:
            df['temp_hour_interaction'] = df['ta'] * df['hour']
            df['temp_season_interaction'] = df['ta'] * df['month']
            print("  ì˜¨ë„ Ã— ì‹œê°„ ìƒí˜¸ì‘ìš© ìƒì„±")
        
        # ê·¹í•œ ê¸°ìƒê³¼ ì‹œê°„ ìƒí˜¸ì‘ìš©
        if 'extreme_weather_any' in df.columns:
            df['extreme_weather_rush'] = df['extreme_weather_any'] * (
                df['time_period'].isin(['morning_rush_peak', 'evening_rush_peak']).astype(int)
            )
            print("  ê·¹í•œê¸°ìƒ Ã— ì¶œí‡´ê·¼ì‹œê°„ ìƒí˜¸ì‘ìš© ìƒì„±")
        
        return df
    
    def create_lag_features(self, df, target_col='congestion'):
        """ì‹œì°¨ íŠ¹ì„± ìƒì„±"""
        print("ğŸ“ˆ ê¸°ìƒ ë³€ìˆ˜ ì‹œì°¨ íŠ¹ì„± ìƒì„± ì¤‘ (í˜¼ì¡ë„ ì‹œì°¨ ì œì™¸)...")
        
        # ì‹œê°„ ì •ë ¬
        df = df.sort_values(['station_name', 'tm']).reset_index(drop=True)
        
        # ê¸°ìƒ ë³€ìˆ˜ ì‹œì°¨ íŠ¹ì„±ë§Œ ìƒì„± (1ì¼ ì „)
        weather_vars = ['ta', 'ws', 'rn_hr1', 'hm']
        for var in weather_vars:
            if var in df.columns:
                df[f'{var}_lag_24'] = df[var].shift(24)
        
        # ê¸°ìƒ ë³€ìˆ˜ ì´ë™í‰ê·  íŠ¹ì„± (3,6,12ì‹œê°„)
        for var in weather_vars:
            if var in df.columns:
                for window in [3, 6, 12]:
                    df[f'{var}_ma_{window}'] = df[var].rolling(
                        window=window, min_periods=1
                    ).mean()
        
        print(f"  ê¸°ìƒ ì‹œì°¨ íŠ¹ì„±: {len(weather_vars)}ê°œ")
        print(f"  ê¸°ìƒ ì´ë™í‰ê·  íŠ¹ì„±: {len(weather_vars) * 3}ê°œ")
        print("  âœ… í˜¼ì¡ë„ ê³¼ê±° ë°ì´í„°ëŠ” ì œì™¸ë¨")
        
        return df

class EnhancedSubwayModel:
    """ê³ ë„í™”ëœ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, use_optuna=True, n_trials=100):
        self.feature_engineer = EnhancedFeatureEngineering()
        self.models = {}
        self.best_model = None
        self.feature_importance = None
        self.use_optuna = use_optuna
        self.n_trials = n_trials
        self.results = {}
        
    def load_and_preprocess_data(self, train_years=['21'], test_year='23', sample_size=5000000):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸš€ ê³ ë„í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            data_dir = os.path.abspath(os.path.join(base_dir, '..', 'ë°ì´í„°'))
            
            # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            train_dfs = []
            for year in train_years:
                file_path = os.path.join(data_dir, f'train_subway{year}.csv')
                print(f"20{year}ë…„ ë°ì´í„° ë¡œë“œ ì¤‘...")
                df = pd.read_csv(file_path, encoding='cp949', nrows=sample_size)
                df.columns = [col.replace(f'train_subway{year}.', '') for col in df.columns]
                train_dfs.append(df)
            
            self.train_data = pd.concat(train_dfs).reset_index(drop=True)
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
            test_file = os.path.join(data_dir, f'train_subway{test_year}.csv')
            print(f"20{test_year}ë…„ ê²€ì¦ ë°ì´í„° ë¡œë“œ ì¤‘...")
            self.test_data = pd.read_csv(test_file, encoding='cp949', nrows=sample_size)
            self.test_data.columns = [col.replace(f'train_subway{test_year}.', '') for col in self.test_data.columns]
            
            # íŠ¹ì„± ê³µí•™ ì ìš©
            print("\nğŸ”§ ê³ ë„í™”ëœ íŠ¹ì„± ê³µí•™ ì ìš© ì¤‘...")
            self.train_data = self._apply_feature_engineering(self.train_data)
            self.test_data = self._apply_feature_engineering(self.test_data)
            
            print(f"\nâœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
            print(f"  í›ˆë ¨ ë°ì´í„°: {len(self.train_data):,}ê°œ")
            print(f"  ê²€ì¦ ë°ì´í„°: {len(self.test_data):,}ê°œ")
            print(f"  íŠ¹ì„± ìˆ˜: {self.train_data.shape[1]}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _apply_feature_engineering(self, df):
        """íŠ¹ì„± ê³µí•™ íŒŒì´í”„ë¼ì¸ ì ìš©"""
        print("ğŸ“Š ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ ìƒíƒœ:")
        print(f"  ì „ì²´ ê²°ì¸¡ì¹˜: {df.isnull().sum().sum():,}ê°œ")
        
        # 0. ê¸°ìƒ ë°ì´í„° íŠ¹ìˆ˜ ê²°ì¸¡ì¹˜ ê°’ ì²˜ë¦¬
        print("\nğŸ”§ ê¸°ìƒ ë°ì´í„° íŠ¹ìˆ˜ ê²°ì¸¡ì¹˜ ê°’ ì²˜ë¦¬...")
        weather_vars = ['ta', 'ws', 'rn_hr1', 'hm','si']
        special_missing_values = [-99, -9999, 999, -999, 9999, -88, -77]
        
        for var in weather_vars:
            if var in df.columns:
                original_missing = df[var].isnull().sum()
                
                # íŠ¹ìˆ˜ ê²°ì¸¡ì¹˜ ê°’ë“¤ì„ NaNìœ¼ë¡œ ë³€í™˜
                for missing_val in special_missing_values:
                    special_count = (df[var] == missing_val).sum()
                    if special_count > 0:
                        print(f"  {var}: {special_count}ê°œì˜ {missing_val} ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜")
                        df[var] = df[var].replace(missing_val, np.nan)
                
                new_missing = df[var].isnull().sum()
                if new_missing != original_missing:
                    print(f"  {var}: ê²°ì¸¡ì¹˜ {original_missing} â†’ {new_missing}ê°œ")
        
        # ë¹„ìƒì‹ì ì¸ ê°’ë“¤ë„ ì²´í¬ (ì˜¨ë„ê°€ -50ë„ ì´í•˜ë‚˜ 60ë„ ì´ìƒ ë“±)
        if 'ta' in df.columns:
            extreme_temp = ((df['ta'] < -50) | (df['ta'] > 60)) & df['ta'].notna()
            if extreme_temp.sum() > 0:
                print(f"  ta: {extreme_temp.sum()}ê°œì˜ ê·¹í•œ ì˜¨ë„ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜")
                df.loc[extreme_temp, 'ta'] = np.nan
        
        if 'hm' in df.columns:
            extreme_hum = ((df['hm'] < 0) | (df['hm'] > 100)) & df['hm'].notna()
            if extreme_hum.sum() > 0:
                print(f"  hm: {extreme_hum.sum()}ê°œì˜ ê·¹í•œ ìŠµë„ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜")
                df.loc[extreme_hum, 'hm'] = np.nan
        
        if 'ws' in df.columns:
            extreme_wind = (df['ws'] < 0) & df['ws'].notna()
            if extreme_wind.sum() > 0:
                print(f"  ws: {extreme_wind.sum()}ê°œì˜ ìŒìˆ˜ í’ì†ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜")
                df.loc[extreme_wind, 'ws'] = np.nan
        
        if 'rn_hr1' in df.columns:
            extreme_rain = (df['rn_hr1'] < 0) & df['rn_hr1'].notna()
            if extreme_rain.sum() > 0:
                print(f"  rn_hr1: {extreme_rain.sum()}ê°œì˜ ìŒìˆ˜ ê°•ìˆ˜ëŸ‰ì„ NaNìœ¼ë¡œ ë³€í™˜")
                df.loc[extreme_rain, 'rn_hr1'] = np.nan
        
        print(f"íŠ¹ìˆ˜ê°’ ì²˜ë¦¬ í›„ ì´ ê²°ì¸¡ì¹˜: {df.isnull().sum().sum():,}ê°œ")
        
        # 1. ê·¹í•œ ê¸°ìƒ íŠ¹ì„±
        df = self.feature_engineer.create_extreme_weather_features(df)
        
        # 2. ì„¸ë¶„í™”ëœ ì‹œê°„ íŠ¹ì„±
        df = self.feature_engineer.create_detailed_time_features(df)
        
        # 3. ìƒí˜¸ì‘ìš© íŠ¹ì„±
        df = self.feature_engineer.create_interaction_features(df)
        
        # 4. ì‹œì°¨ íŠ¹ì„± (ê¸°ìƒ ë³€ìˆ˜ë§Œ, í˜¼ì¡ë„ ì‹œì°¨ëŠ” ì œì™¸)
        if 'congestion' in df.columns:
            print("ğŸ“ˆ ê¸°ìƒ ë³€ìˆ˜ ì‹œì°¨ íŠ¹ì„± ìƒì„± ì¤‘ (í˜¼ì¡ë„ ì‹œì°¨ ì œì™¸)...")
            
            # ì‹œê°„ ì •ë ¬
            df = df.sort_values(['station_name', 'tm']).reset_index(drop=True)
            
            # ê¸°ìƒ ë³€ìˆ˜ ì‹œì°¨ íŠ¹ì„±ë§Œ ìƒì„± (1ì¼ ì „)
            weather_vars = ['ta', 'ws', 'rn_hr1', 'hm']
            for var in weather_vars:
                if var in df.columns:
                    df[f'{var}_lag_24'] = df[var].shift(24)
            
            # ê¸°ìƒ ë³€ìˆ˜ ì´ë™í‰ê·  íŠ¹ì„± (3,6,12ì‹œê°„)
            for var in weather_vars:
                if var in df.columns:
                    for window in [3, 6, 12]:
                        df[f'{var}_ma_{window}'] = df[var].rolling(
                            window=window, min_periods=1
                        ).mean()
            
            print(f"  ê¸°ìƒ ì‹œì°¨ íŠ¹ì„±: {len(weather_vars)}ê°œ")
            print(f"  ê¸°ìƒ ì´ë™í‰ê·  íŠ¹ì„±: {len(weather_vars) * 3}ê°œ")
            print("  âœ… í˜¼ì¡ë„ ê³¼ê±° ë°ì´í„°ëŠ” ì œì™¸ë¨")
        
        # 5. ì²´ê³„ì ì¸ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        print("\nğŸ”§ ì²´ê³„ì ì¸ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘...")
        
        # 5-1. ê¸°ìƒ ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì‹œê³„ì—´ íŠ¹ì„± ê³ ë ¤)
        if 'datetime' in df.columns:
            df = df.sort_values(['station_name', 'datetime']).reset_index(drop=True)
            
            for var in weather_vars:
                if var in df.columns:
                    missing_before = df[var].isnull().sum()
                    if missing_before > 0:
                        # Forward fill -> Backward fill -> Median
                        df[var] = df.groupby('station_name')[var].fillna(method='ffill').fillna(method='bfill')
                        df[var] = df[var].fillna(df[var].median())
                        missing_after = df[var].isnull().sum()
                        print(f"  {var}: {missing_before} â†’ {missing_after} ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-2. ì‹œì°¨ íŠ¹ì„± ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì‹œê³„ì—´ íŠ¹ì„± íŠ¹ë³„ ì²˜ë¦¬)
        lag_cols = [col for col in df.columns if 'lag_' in col or '_ma_' in col]
        for col in lag_cols:
            missing_before = df[col].isnull().sum()
            if missing_before > 0:
                # ì‹œì°¨ íŠ¹ì„±ì€ 0ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
                if 'congestion' in col:
                    # í˜¼ì¡ë„ ì‹œì°¨ëŠ” í•´ë‹¹ ì—­ì˜ í‰ê· ê°’ìœ¼ë¡œ
                    df[col] = df.groupby('station_name')[col].transform(
                        lambda x: x.fillna(x.mean()) if x.notna().any() else x.fillna(50)
                    )
                else:
                    # ê¸°ìƒ ì‹œì°¨ëŠ” ì›ë³¸ ë³€ìˆ˜ ê°’ìœ¼ë¡œ
                    base_var = col.split('_lag_')[0] if '_lag_' in col else col.split('_ma_')[0]
                    if base_var in df.columns:
                        df[col] = df[col].fillna(df[base_var])
                    else:
                        df[col] = df[col].fillna(0)
                
                missing_after = df[col].isnull().sum()
                if missing_before > 0:
                    print(f"  {col}: {missing_before} â†’ {missing_after} ì‹œì°¨ ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-3. ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        categorical_vars = ['time_period', 'detailed_season', 'day_type']
        for var in categorical_vars:
            if var in df.columns:
                missing_before = df[var].isnull().sum()
                if missing_before > 0:
                    # ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                    mode_value = df[var].mode()
                    if len(mode_value) > 0:
                        df[var] = df[var].fillna(mode_value[0])
                    missing_after = df[var].isnull().sum()
                    print(f"  {var}: {missing_before} â†’ {missing_after} ë²”ì£¼í˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-4. ì´ì§„ ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê·¹í•œ ê¸°ìƒ ë“±)
        binary_vars = [col for col in df.columns if col.startswith(('extreme_', 'is_', 'no_', 'light_', 'heavy_', 'strong_', 'calm_'))]
        for var in binary_vars:
            missing_before = df[var].isnull().sum()
            if missing_before > 0:
                df[var] = df[var].fillna(0)  # ì´ì§„ ë³€ìˆ˜ëŠ” 0ìœ¼ë¡œ
                missing_after = df[var].isnull().sum()
                if missing_before > 0:
                    print(f"  {var}: {missing_before} â†’ {missing_after} ì´ì§„ ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-5. ìƒí˜¸ì‘ìš© íŠ¹ì„± ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        interaction_vars = [col for col in df.columns if 'interaction' in col or 'apparent_temp' in col or 'wind_chill' in col]
        for var in interaction_vars:
            missing_before = df[var].isnull().sum()
            if missing_before > 0:
                df[var] = df[var].fillna(df[var].median())
                missing_after = df[var].isnull().sum()
                if missing_before > 0:
                    print(f"  {var}: {missing_before} â†’ {missing_after} ìƒí˜¸ì‘ìš© ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-6. ìˆ«ìí˜• ë³€ìˆ˜ ìµœì¢… ì²˜ë¦¬ (median)
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if df[col].isnull().sum() > 0:
                missing_before = df[col].isnull().sum()
                df[col] = df[col].fillna(df[col].median())
                missing_after = df[col].isnull().sum()
                if missing_before > 0:
                    print(f"  {col}: {missing_before} â†’ {missing_after} ê¸°íƒ€ ìˆ«ìí˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        
        # 5-7. ìµœì¢… ê²°ì¸¡ì¹˜ í™•ì¸
        final_missing = df.isnull().sum().sum()
        print(f"\nâœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {final_missing}ê°œ ë‚¨ìŒ")
        
        if final_missing > 0:
            print("âš ï¸ ë‚¨ì€ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼:")
            missing_cols = df.columns[df.isnull().any()].tolist()
            for col in missing_cols:
                missing_count = df[col].isnull().sum()
                missing_pct = missing_count / len(df) * 100
                print(f"  {col}: {missing_count}ê°œ ({missing_pct:.1f}%)")
        
        return df
    
    def prepare_features(self):
        """ìµœì¢… íŠ¹ì„± ì¤€ë¹„"""
        print("\nğŸ¯ ìµœì¢… íŠ¹ì„± ì¤€ë¹„ ì¤‘...")
        
        # ê³µí†µ ì—­ í•„í„°ë§
        train_stations = set(self.train_data['station_name'].unique())
        test_stations = set(self.test_data['station_name'].unique())
        common_stations = train_stations & test_stations
        
        print(f"ê³µí†µ ì—­: {len(common_stations)}ê°œ")
        
        self.train_data = self.train_data[self.train_data['station_name'].isin(common_stations)]
        self.test_data = self.test_data[self.test_data['station_name'].isin(common_stations)]
        
        # ì—­ ì¸ì½”ë”©
        le_station = LabelEncoder()
        le_station.fit(sorted(common_stations))
        self.train_data['station_encoded'] = le_station.transform(self.train_data['station_name'])
        self.test_data['station_encoded'] = le_station.transform(self.test_data['station_name'])
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_cols = ['time_period', 'detailed_season', 'day_type']
        for col in categorical_cols:
            if col in self.train_data.columns:
                le = LabelEncoder()
                # í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ëª¨ë“  ê°’ìœ¼ë¡œ fit
                combined_values = pd.concat([self.train_data[col], self.test_data[col]]).unique()
                le.fit(combined_values)
                self.train_data[f'{col}_encoded'] = le.transform(self.train_data[col])
                self.test_data[f'{col}_encoded'] = le.transform(self.test_data[col])
        
        # ëª…ì‹œì ìœ¼ë¡œ ì œì™¸í•  ì»¬ëŸ¼ë“¤ ì •ì˜
        exclude_cols = [
            'tm', 'datetime', 'station_name', 'congestion',
            'time_period', 'detailed_season', 'day_type'  # ì¸ì½”ë”©ëœ ë²„ì „ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì›ë³¸ ì œì™¸
        ]
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ (ë” ì•ˆì „í•œ ë°©ë²•)
        numeric_cols = self.train_data.select_dtypes(include=[np.number]).columns.tolist()
        
        # íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ: ìˆ«ìí˜•ì´ë©´ì„œ ì œì™¸ ëª©ë¡ì— ì—†ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë„ ìˆëŠ” ì»¬ëŸ¼ë“¤
        feature_cols = [col for col in numeric_cols 
                       if col not in exclude_cols and col in self.test_data.columns]
        
        print(f"ì „ì²´ ìˆ«ìí˜• ì»¬ëŸ¼: {len(numeric_cols)}ê°œ")
        print(f"ì œì™¸ëœ ì»¬ëŸ¼: {len([col for col in numeric_cols if col in exclude_cols])}ê°œ")
        
        # ê²°ì¸¡ì¹˜ê°€ ë§ì€ íŠ¹ì„± ì œê±°
        missing_threshold = 0.5
        features_to_remove = []
        for col in feature_cols.copy():
            train_missing = self.train_data[col].isnull().mean()
            test_missing = self.test_data[col].isnull().mean()
            if train_missing > missing_threshold or test_missing > missing_threshold:
                features_to_remove.append(col)
                feature_cols.remove(col)
                print(f"ì œê±°: {col} (í›ˆë ¨ ê²°ì¸¡ì¹˜ {train_missing:.1%}, í…ŒìŠ¤íŠ¸ ê²°ì¸¡ì¹˜ {test_missing:.1%})")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ì•ˆì „ì„± ê²€ì¦
        print(f"\në°ì´í„° íƒ€ì… ê²€ì¦:")
        for col in feature_cols[:5]:  # ì²˜ìŒ 5ê°œë§Œ í™•ì¸
            train_dtype = self.train_data[col].dtype
            test_dtype = self.test_data[col].dtype
            print(f"  {col}: í›ˆë ¨={train_dtype}, í…ŒìŠ¤íŠ¸={test_dtype}")
        
        # ìµœì¢… íŠ¹ì„± ë°ì´í„° ìƒì„±
        X_train = self.train_data[feature_cols].copy()
        y_train = self.train_data['congestion'].copy()
        X_test = self.test_data[feature_cols].copy()
        y_test = self.test_data['congestion'].copy()
        
        # ë¬¸ìì—´ì´ ì„ì—¬ìˆëŠ”ì§€ ìµœì¢… í™•ì¸
        for col in feature_cols:
            if X_train[col].dtype == 'object':
                print(f"âš ï¸ ê²½ê³ : {col}ì´ ë¬¸ìì—´ íƒ€ì…ì…ë‹ˆë‹¤. ìƒ˜í”Œ: {X_train[col].head().tolist()}")
                # ë¬¸ìì—´ ì»¬ëŸ¼ì´ë©´ ì œê±°
                feature_cols.remove(col)
                X_train = X_train.drop(columns=[col])
                X_test = X_test.drop(columns=[col])
        
        # LightGBM í˜¸í™˜ì„±ì„ ìœ„í•œ ì»¬ëŸ¼ëª… ì •ë¦¬
        print(f"\nğŸ”§ LightGBM í˜¸í™˜ì„±ì„ ìœ„í•œ ì»¬ëŸ¼ëª… ì •ë¦¬ ì¤‘...")
        def clean_feature_name(name):
            """íŠ¹ìˆ˜ë¬¸ìë¥¼ ì•ˆì „í•œ ë¬¸ìë¡œ ì¹˜í™˜"""
            # íŠ¹ìˆ˜ë¬¸ìë“¤ì„ ì•ˆì „í•œ ë¬¸ìë¡œ ì¹˜í™˜
            replacements = {
                '%': 'pct',
                '(': '_',
                ')': '_',
                '[': '_',
                ']': '_',
                ':': '_',
                ' ': '_',
                '-': '_',
                '/': '_',
                '.': '_',
                ',': '_',
                '&': 'and',
                '+': 'plus',
                '*': 'mult',
                '=': 'eq',
                '<': 'lt',
                '>': 'gt',
                '!': 'not',
                '?': 'q',
                '@': 'at',
                '#': 'hash',
                '$': 'dollar'
            }
            
            cleaned_name = name
            for old_char, new_char in replacements.items():
                cleaned_name = cleaned_name.replace(old_char, new_char)
            
            # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ ì •ë¦¬
            while '__' in cleaned_name:
                cleaned_name = cleaned_name.replace('__', '_')
            
            # ì‹œì‘ê³¼ ëì˜ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
            cleaned_name = cleaned_name.strip('_')
            
            return cleaned_name
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬ ë° ë³€ê²½ì‚¬í•­ ì¶”ì 
        original_feature_cols = feature_cols.copy()
        cleaned_feature_cols = [clean_feature_name(col) for col in feature_cols]
        
        # ë³€ê²½ëœ ì»¬ëŸ¼ëª…ì´ ìˆëŠ”ì§€ í™•ì¸
        changes_made = False
        for original, cleaned in zip(original_feature_cols, cleaned_feature_cols):
            if original != cleaned:
                if not changes_made:
                    print("  ì»¬ëŸ¼ëª… ë³€ê²½ ì‚¬í•­:")
                    changes_made = True
                print(f"    {original} â†’ {cleaned}")
        
        if not changes_made:
            print("  âœ… ëª¨ë“  ì»¬ëŸ¼ëª…ì´ ì´ë¯¸ ì•ˆì „í•¨")
        
        # DataFrame ì»¬ëŸ¼ëª… ë³€ê²½
        column_mapping = dict(zip(original_feature_cols, cleaned_feature_cols))
        X_train = X_train.rename(columns=column_mapping)
        X_test = X_test.rename(columns=column_mapping)
        feature_cols = cleaned_feature_cols
        
        print(f"\nìµœì¢… íŠ¹ì„± ìˆ˜: {len(feature_cols)}ê°œ")
        print(f"íŠ¹ì„± ì¢…ë¥˜: ê¸°ë³¸ì‹œê°„, ê·¹í•œê¸°ìƒ, ìƒí˜¸ì‘ìš©, ê¸°ìƒì‹œì°¨, ì¸ì½”ë”©")
        print(f"í›ˆë ¨ ë°ì´í„° í˜•íƒœ: {X_train.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ: {X_test.shape}")
        
        return X_train, y_train, X_test, y_test, feature_cols
    
    def hyperparameter_tuning(self, X_train, y_train, model_type='xgboost'):
        """Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        print(f"\nğŸ” {model_type} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
        
        def objective(trial):
            if model_type == 'xgboost':
                params = {
                    'objective': 'reg:squarederror',
                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                    'max_depth': trial.suggest_int('max_depth', 3, 12),
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
                    'random_state': 42
                }
                model = xgb.XGBRegressor(**params)
                
            elif model_type == 'lightgbm':
                params = {
                    'objective': 'regression',
                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                    'max_depth': trial.suggest_int('max_depth', 3, 12),
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                    'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
                    'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
                    'random_state': 42,
                    'verbosity': -1
                }
                model = lgb.LGBMRegressor(**params)
            
            # ì‹œê³„ì—´ êµì°¨ê²€ì¦
            tscv = TimeSeriesSplit(n_splits=3)
            cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, 
                                      scoring='neg_mean_absolute_error', n_jobs=-1)
            return cv_scores.mean()
        
        # Optuna ìŠ¤í„°ë””
        study = optuna.create_study(direction='maximize', 
                                  sampler=optuna.samplers.TPESampler(seed=42))
        study.optimize(objective, n_trials=self.n_trials, show_progress_bar=True)
        
        print(f"ìµœì  íŒŒë¼ë¯¸í„°: {study.best_params}")
        print(f"ìµœì  CV ì ìˆ˜: {study.best_value:.4f}")
        
        return study.best_params
    
    def feature_selection(self, X_train, y_train, X_test, feature_cols, method='simple'):
        """ë¹ ë¥¸ íŠ¹ì„± ì„ íƒ"""
        print(f"\nğŸ¯ ë¹ ë¥¸ íŠ¹ì„± ì„ íƒ ({method}) ì¤‘...")
        
        if method == 'simple' or len(feature_cols) < 20:
            # ê°„ë‹¨í•œ ë°©ë²•: ë¶„ì‚°ì´ ë„ˆë¬´ ë‚®ì€ íŠ¹ì„±ë§Œ ì œê±°
            from sklearn.feature_selection import VarianceThreshold
            
            # ë¶„ì‚° ì„ê³„ê°’ìœ¼ë¡œ íŠ¹ì„± ì„ íƒ (ë§¤ìš° ë¹ ë¦„)
            selector = VarianceThreshold(threshold=0.01)
            X_train_transformed = selector.fit_transform(X_train)
            X_test_transformed = selector.transform(X_test)
            
            selected_features = [feature_cols[i] for i, selected in enumerate(selector.get_support()) if selected]
            
            print(f"ë¶„ì‚° ê¸°ë°˜ ì„ íƒ: {len(selected_features)}ê°œ (ì „ì²´ {len(feature_cols)}ê°œ ì¤‘)")
            
            X_train_selected = pd.DataFrame(X_train_transformed, columns=selected_features, index=X_train.index)
            X_test_selected = pd.DataFrame(X_test_transformed, columns=selected_features, index=X_test.index)
            
        else:
            # ê¸°ì¡´ ì¤‘ìš”ë„ ê¸°ë°˜ ë°©ë²• (ë” ëŠë¦¼)
            rf = RandomForestRegressor(n_estimators=20, random_state=42, n_jobs=1)  # ë” ë¹ ë¥´ê²Œ
            rf.fit(X_train, y_train)
            
            importances = rf.feature_importances_
            feature_importance_df = pd.DataFrame({
                'feature': feature_cols,
                'importance': importances
            }).sort_values('importance', ascending=False)
            
            threshold = 0.005  # ì„ê³„ê°’ ì™„í™”
            selected_features = feature_importance_df[
                feature_importance_df['importance'] >= threshold
            ]['feature'].tolist()
            
            print(f"ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ: {len(selected_features)}ê°œ")
            
            X_train_selected = X_train[selected_features]
            X_test_selected = X_test[selected_features]
        
        self.selected_features = selected_features
        return X_train_selected, X_test_selected, selected_features
    
    def train_enhanced_models(self, X_train, y_train, X_test, y_test):
        """ê³ ë„í™”ëœ ëª¨ë¸ë“¤ í›ˆë ¨ (XGBoost, LightGBMë§Œ)"""
        print("\nğŸš€ ê³ ë„í™”ëœ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print("=" * 50)
        
        models_to_train = {
            'Enhanced_XGBoost': 'xgboost',
            'Enhanced_LightGBM': 'lightgbm'
        }
        
        for model_name, model_type in models_to_train.items():
            print(f"\nğŸ”§ {model_name} í›ˆë ¨ ì¤‘...")
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
            if self.use_optuna:
                best_params = self.hyperparameter_tuning(X_train, y_train, model_type)
            else:
                # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©
                if model_type == 'xgboost':
                    best_params = {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}
                elif model_type == 'lightgbm':
                    best_params = {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}
            
            # ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
            if model_type == 'xgboost':
                model = xgb.XGBRegressor(**best_params)
            elif model_type == 'lightgbm':
                model = lgb.LGBMRegressor(**best_params)
            
            model.fit(X_train, y_train)
            
            # ì˜ˆì¸¡ ë° í‰ê°€
            y_pred = model.predict(X_test)
            
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            
            self.models[model_name] = model
            self.results[model_name] = {
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'params': best_params
            }
            
            print(f"  MAE: {mae:.3f}")
            print(f"  RMSE: {rmse:.3f}")
            print(f"  RÂ²: {r2:.3f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])
        self.best_model = self.models[best_model_name]
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
        print(f"  MAE: {self.results[best_model_name]['mae']:.3f}")
        print(f"  RÂ²: {self.results[best_model_name]['r2']:.3f}")
        
        return self.results
    
    def analyze_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"""
        print("\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
        print("=" * 40)
        
        if self.best_model is None:
            print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ
        if hasattr(self.best_model, 'feature_importances_'):
            importances = self.best_model.feature_importances_
        else:
            print("âŒ ëª¨ë¸ì´ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        importance_df = pd.DataFrame({
            'feature': self.selected_features,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        self.feature_importance = importance_df
        
        # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¶œë ¥
        print("ìƒìœ„ 20ê°œ ì¤‘ìš” íŠ¹ì„±:")
        for i, row in importance_df.head(20).iterrows():
            print(f"  {row['feature']}: {row['importance']:.4f}")
        
        return importance_df
    
    def plot_results(self):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ê³ ë„í™”ëœ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # 1) ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_names = list(self.results.keys())
        mae_scores = [self.results[name]['mae'] for name in model_names]
        r2_scores = [self.results[name]['r2'] for name in model_names]
        
        axes[0, 0].bar(model_names, mae_scores, color='skyblue', alpha=0.7)
        axes[0, 0].set_title('ëª¨ë¸ë³„ MAE ë¹„êµ')
        axes[0, 0].set_ylabel('Mean Absolute Error')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        axes[0, 1].bar(model_names, r2_scores, color='lightgreen', alpha=0.7)
        axes[0, 1].set_title('ëª¨ë¸ë³„ RÂ² ë¹„êµ')
        axes[0, 1].set_ylabel('RÂ² Score')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 2) íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)
        if self.feature_importance is not None:
            top_features = self.feature_importance.head(15)
            axes[0, 2].barh(top_features['feature'][::-1], top_features['importance'][::-1])
            axes[0, 2].set_title('íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)')
            axes[0, 2].set_xlabel('ì¤‘ìš”ë„')
        
        # 3) ì˜ˆì¸¡ vs ì‹¤ì œ (ìµœê³  ëª¨ë¸)
        if self.best_model is not None:
            X_train, y_train, X_test, y_test, _ = self.prepare_features()
            if self.selected_features:
                X_test = X_test[self.selected_features]
            
            y_pred = self.best_model.predict(X_test)
            
            # ìƒ˜í”Œë§ (ì‹œê°í™” ìµœì í™”)
            if len(y_test) > 10000:
                sample_idx = np.random.choice(len(y_test), 10000, replace=False)
                y_test_sample = y_test.iloc[sample_idx]
                y_pred_sample = y_pred[sample_idx]
            else:
                y_test_sample = y_test
                y_pred_sample = y_pred
            
            axes[1, 0].scatter(y_test_sample, y_pred_sample, alpha=0.5, s=1)
            axes[1, 0].plot([y_test_sample.min(), y_test_sample.max()], 
                           [y_test_sample.min(), y_test_sample.max()], 'r--', lw=2)
            axes[1, 0].set_xlabel('ì‹¤ì œ í˜¼ì¡ë„')
            axes[1, 0].set_ylabel('ì˜ˆì¸¡ í˜¼ì¡ë„')
            axes[1, 0].set_title('ì˜ˆì¸¡ vs ì‹¤ì œ (ìµœê³  ëª¨ë¸)')
            
            # 4) ì”ì°¨ ë¶„í¬
            residuals = y_test_sample - y_pred_sample
            axes[1, 1].hist(residuals, bins=50, alpha=0.7, color='orange')
            axes[1, 1].set_xlabel('ì”ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)')
            axes[1, 1].set_ylabel('ë¹ˆë„')
            axes[1, 1].set_title('ì”ì°¨ ë¶„í¬')
            axes[1, 1].axvline(0, color='red', linestyle='--')
            
            # 5) ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥
            test_data_with_pred = self.test_data.copy()
            test_data_with_pred['predictions'] = self.best_model.predict(X_test)
            test_data_with_pred['residuals'] = abs(test_data_with_pred['congestion'] - test_data_with_pred['predictions'])
            
            hourly_mae = test_data_with_pred.groupby('hour')['residuals'].mean()
            axes[1, 2].plot(hourly_mae.index, hourly_mae.values, marker='o', linewidth=2)
            axes[1, 2].set_title('ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ì˜¤ì°¨ (MAE)')
            axes[1, 2].set_xlabel('ì‹œê°„')
            axes[1, 2].set_ylabel('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨')
            axes[1, 2].grid(True, alpha=0.3)
            axes[1, 2].set_xticks(range(0, 24, 2))
        
        plt.tight_layout()
        plt.savefig('../result/enhanced_model_results.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_model(self, filename='enhanced_subway_model.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        model_data = {
            'best_model': self.best_model,
            'feature_engineer': self.feature_engineer,
            'selected_features': self.selected_features,
            'results': self.results,
            'feature_importance': self.feature_importance
        }
        
        joblib.dump(model_data, filename)
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filename}")
    
    def generate_insights(self):
        """ê°œì„ ëœ ëª¨ë¸ ì¸ì‚¬ì´íŠ¸"""
        print("\n" + "=" * 60)
        print("ğŸš€ ê³ ë„í™”ëœ ëª¨ë¸ ì¸ì‚¬ì´íŠ¸")
        print("=" * 60)
        
        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])
        best_result = self.results[best_model_name]
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
        print(f"  ğŸ“Š MAE: {best_result['mae']:.3f}")
        print(f"  ğŸ“Š RMSE: {best_result['rmse']:.3f}")
        print(f"  ğŸ“Š RÂ²: {best_result['r2']:.3f}")
        
        # ì„±ëŠ¥ ê°œì„  ë¶„ì„
        print(f"\nğŸ“ˆ ëª¨ë¸ ê°œì„  íš¨ê³¼:")
        if best_result['r2'] > 0.8:
            print("  âœ… ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì„±ëŠ¥ ë‹¬ì„±")
        elif best_result['r2'] > 0.6:
            print("  â­ ì–‘í˜¸í•œ ì˜ˆì¸¡ ì„±ëŠ¥")
        else:
            print("  ğŸ”§ ì¶”ê°€ ê°œì„  í•„ìš”")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¸ì‚¬ì´íŠ¸
        if self.feature_importance is not None:
            print(f"\nğŸ¯ í•µì‹¬ ì˜ˆì¸¡ ìš”ì¸ (ìƒìœ„ 5ê°œ):")
            for i, row in self.feature_importance.head(5).iterrows():
                print(f"  {i+1}. {row['feature']}: {row['importance']:.3f}")
            
            # íŠ¹ì„± ìœ í˜•ë³„ ë¶„ì„
            importance_by_type = {}
            for _, row in self.feature_importance.iterrows():
                feature = row['feature']
                if any(x in feature for x in ['extreme_', 'heavy_', 'strong_']):
                    importance_by_type['ê·¹í•œê¸°ìƒ'] = importance_by_type.get('ê·¹í•œê¸°ìƒ', 0) + row['importance']
                elif any(x in feature for x in ['interaction', '_x_', 'temp_humidity']):
                    importance_by_type['ìƒí˜¸ì‘ìš©'] = importance_by_type.get('ìƒí˜¸ì‘ìš©', 0) + row['importance']
                elif any(x in feature for x in ['lag_', '_ma_', 'shift']):
                    importance_by_type['ì‹œì°¨íŠ¹ì„±'] = importance_by_type.get('ì‹œì°¨íŠ¹ì„±', 0) + row['importance']
                elif any(x in feature for x in ['hour', 'day', 'time_period', 'season']):
                    importance_by_type['ì‹œê°„íŠ¹ì„±'] = importance_by_type.get('ì‹œê°„íŠ¹ì„±', 0) + row['importance']
                else:
                    importance_by_type['ê¸°ë³¸íŠ¹ì„±'] = importance_by_type.get('ê¸°ë³¸íŠ¹ì„±', 0) + row['importance']
            
            print(f"\nğŸ“Š íŠ¹ì„± ìœ í˜•ë³„ ì¤‘ìš”ë„:")
            for feature_type, importance in sorted(importance_by_type.items(), key=lambda x: x[1], reverse=True):
                print(f"  {feature_type}: {importance:.3f}")
        
        print(f"\nğŸ’¡ ì‹¤ë¬´ í™œìš© ì œì•ˆ:")
        print("  ğŸ¯ ê·¹í•œ ê¸°ìƒ ì¡°ê±´ì—ì„œì˜ í˜¼ì¡ë„ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ")
        print("  ğŸ¯ ì„¸ë¶„í™”ëœ ì‹œê°„ëŒ€ë³„ ë§ì¶¤í˜• ìš´ì˜ ì „ëµ ìˆ˜ë¦½")
        print("  ğŸ¯ ê¸°ìƒ-ì‹œê°„ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•œ ë™ì  ë°°ì°¨ ê³„íš")
        print("  ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ í•µì‹¬ ìš”ì¸ ëª¨ë‹ˆí„°ë§")

    def separate_time_effects(self, method='residual'):
        """ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬"""
        print(f"\nğŸ• ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ì‹œì‘ ({method} ë°©ë²•)")
        print("=" * 50)
        
        if method == 'residual':
            return self._residual_based_separation()
        elif method == 'decompose':
            return self._seasonal_decompose_separation()
        else:
            print("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 'residual' ë˜ëŠ” 'decompose'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            return None
    
    def _residual_based_separation(self):
        """ì”ì°¨ ê¸°ë°˜ ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬"""
        print("ğŸ“Š ì”ì°¨ ê¸°ë°˜ ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ì¤‘...")
        
        # ì‹œê°„ ë³€ìˆ˜ë§Œìœ¼ë¡œ ê°„ë‹¨ ëª¨ë¸ í•™ìŠµ
        time_features = ['hour', 'dayofweek', 'month', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']
        available_time_features = [f for f in time_features if f in self.train_data.columns]
        
        print(f"ì‹œê°„ íŠ¹ì„±: {available_time_features}")
        
        # ì‹œê°„ ëª¨ë¸ í•™ìŠµ
        from sklearn.ensemble import RandomForestRegressor
        time_model = RandomForestRegressor(n_estimators=100, random_state=42)
        
        X_time_train = self.train_data[available_time_features]
        y_time_train = self.train_data['congestion']
        X_time_test = self.test_data[available_time_features]
        y_time_test = self.test_data['congestion']
        
        time_model.fit(X_time_train, y_time_train)
        
        # ì‹œê°„ íš¨ê³¼ ì˜ˆì¸¡
        time_pred_train = time_model.predict(X_time_train)
        time_pred_test = time_model.predict(X_time_test)
        
        # ì”ì°¨ ê³„ì‚° (ì‹œê°„ íš¨ê³¼ ì œê±°)
        self.train_data['congestion_residual'] = y_time_train - time_pred_train
        self.test_data['congestion_residual'] = y_time_test - time_pred_test
        
        print(f"ì‹œê°„ ëª¨ë¸ RÂ²: {time_model.score(X_time_train, y_time_train):.3f}")
        print(f"ì›ë³¸ í˜¼ì¡ë„ ë¶„ì‚°: {y_time_train.var():.3f}")
        print(f"ì”ì°¨ ë¶„ì‚°: {self.train_data['congestion_residual'].var():.3f}")
        print(f"ì‹œê°„ íš¨ê³¼ ì œê±°ìœ¨: {(1 - self.train_data['congestion_residual'].var()/y_time_train.var())*100:.1f}%")
        
        return time_model
    
    def _seasonal_decompose_separation(self):
        """ì‹œê³„ì—´ ë¶„í•´ ê¸°ë°˜ ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬"""
        print("ğŸ“ˆ ì‹œê³„ì—´ ë¶„í•´ ê¸°ë°˜ ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ì¤‘...")
        
        try:
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            # ì—­ë³„ë¡œ ì‹œê³„ì—´ ë¶„í•´
            for data_name, data in [('train', self.train_data), ('test', self.test_data)]:
                print(f"{data_name} ë°ì´í„° ë¶„í•´ ì¤‘...")
                
                residuals = []
                for station in data['station_name'].unique():
                    station_data = data[data['station_name'] == station].sort_values('tm')
                    
                    if len(station_data) >= 48:  # ìµœì†Œ 2ì¼ ë°ì´í„°
                        try:
                            # ì‹œê³„ì—´ ë¶„í•´ (24ì‹œê°„ ì£¼ê¸°)
                            decomposition = seasonal_decompose(
                                station_data['congestion'], 
                                model='additive', 
                                period=24,
                                extrapolate_trend='freq'
                            )
                            
                            station_residuals = decomposition.resid.fillna(0)
                            residuals.extend(zip(station_data.index, station_residuals))
                            
                        except Exception as e:
                            print(f"âš ï¸ {station} ì—­ ë¶„í•´ ì‹¤íŒ¨: {str(e)}")
                            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ê°’ ì‚¬ìš©
                            residuals.extend(zip(station_data.index, station_data['congestion']))
                    else:
                        # ë°ì´í„° ë¶€ì¡± ì‹œ ì›ë³¸ê°’ ì‚¬ìš©  
                        residuals.extend(zip(station_data.index, station_data['congestion']))
                
                # ì”ì°¨ ì„¤ì •
                residual_dict = dict(residuals)
                data['congestion_residual'] = data.index.map(residual_dict).fillna(data['congestion'])
                
                print(f"{data_name} ì›ë³¸ ë¶„ì‚°: {data['congestion'].var():.3f}")
                print(f"{data_name} ì”ì°¨ ë¶„ì‚°: {data['congestion_residual'].var():.3f}")
                
        except ImportError:
            print("âš ï¸ statsmodels ë¯¸ì„¤ì¹˜. pip install statsmodels")
            return self._residual_based_separation()  # ëŒ€ì•ˆ ì‚¬ìš©
            
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ í¬í•¨"""
    print("ğŸš€ ê³ ë„í™”ëœ ì§€í•˜ì²  í˜¼ì¡ë„ ì˜ˆì¸¡ ëª¨ë¸ (ì‹œê°„íš¨ê³¼ë¶„ë¦¬)")
    print("=" * 60)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = EnhancedSubwayModel(use_optuna=True, n_trials=10)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    if not model.load_and_preprocess_data(train_years=['21'], test_year='23', sample_size=5000000):
        return None
    
    # 2. ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ (ì˜µì…˜)
    use_time_separation = True  # ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ì‚¬ìš© ì—¬ë¶€
    separation_method = 'residual'  # 'residual' ë˜ëŠ” 'decompose'
    
    if use_time_separation:
        model.separate_time_effects(method=separation_method)
        target_col = 'congestion_residual'  # ì”ì°¨ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ì‚¬ìš©
        print(f"âœ… íƒ€ê²Ÿ ë³€ìˆ˜: {target_col} (ì‹œê°„ íš¨ê³¼ ì œê±°ë¨)")
    else:
        target_col = 'congestion'  # ì›ë³¸ ì‚¬ìš©
        print(f"âœ… íƒ€ê²Ÿ ë³€ìˆ˜: {target_col} (ì›ë³¸)")
    
    # 3. íŠ¹ì„± ì¤€ë¹„ (ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ëœ íƒ€ê²Ÿ ì‚¬ìš©)
    original_congestion = model.train_data['congestion'].copy()
    model.train_data['congestion'] = model.train_data[target_col]
    model.test_data['congestion'] = model.test_data[target_col]
    
    X_train, y_train, X_test, y_test, feature_cols = model.prepare_features()
    
    # 4. íŠ¹ì„± ì„ íƒ
    X_train_selected, X_test_selected, selected_features = model.feature_selection(
        X_train, y_train, X_test, feature_cols, method='simple'
    )
    
    # 5. ëª¨ë¸ í›ˆë ¨
    results = model.train_enhanced_models(X_train_selected, y_train, X_test_selected, y_test)
    
    # 6. ë¶„ì„ ë° ì €ì¥
    model.analyze_feature_importance()
    
    try:
        filename = f'enhanced_model_{"time_separated" if use_time_separation else "original"}.pkl'
        model.save_model(filename)
    except:
        model.save_model('enhanced_model_time_separated.pkl')
    
    model.generate_insights()
    
    # ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ê²°ê³¼ ìš”ì•½
    if use_time_separation:
        print(f"\nğŸ• ì‹œê°„ íš¨ê³¼ ë¶„ë¦¬ ìš”ì•½:")
        print(f"  ë°©ë²•: {separation_method}")
        print(f"  ì‹œê°„ íš¨ê³¼ ì œê±°ë¡œ ê¸°ìƒë³€ìˆ˜ ì˜í–¥ ë” ëª…í™•íˆ ë¶„ì„ ê°€ëŠ¥")
        
    print(f"\nğŸ‰ ì‹œê°„íš¨ê³¼ ë¶„ë¦¬ ëª¨ë¸ ì™„ë£Œ!")
    return model

if __name__ == "__main__":
    enhanced_model = main() 