import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import warnings
import os
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class TimeSeriesValidator:
    """2021â†’2023 ì‹œê³„ì—´ ê²€ì¦"""
    
    def __init__(self):
        self.train_data = None
        self.test_data = None
        self.models = {}
        self.results = {}
        
    def load_data(self, train_years=['21', '22'], test_year='23', sample_size=5000000):
        """ë³µìˆ˜ í•™ìŠµ ë°ì´í„°(21,22ë…„)ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°(23ë…„) ë¡œë“œ"""
        print(f"ğŸš€ ì‹œê³„ì—´ ê²€ì¦ ë°ì´í„° ë¡œë“œ")
        print(f"  í›ˆë ¨: {', '.join('20'+y for y in train_years)}ë…„ ë°ì´í„°")
        print(f"  ê²€ì¦: 20{test_year}ë…„ ë°ì´í„°")
        print("="*60)

        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            data_dir = os.path.abspath(os.path.join(base_dir, '..', 'ë°ì´í„°'))
            
            # ì—¬ëŸ¬ í•™ìŠµ ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ concat
            train_dfs = []
            for y in train_years:
                train_file = os.path.join(data_dir, f'train_subway{y}.csv')
                print(f"20{y}ë…„ í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì¤‘...")
                df = pd.read_csv(train_file, encoding='cp949', nrows=sample_size)
                df = self._preprocess_data(df, y)
                train_dfs.append(df)
            self.train_data = pd.concat(train_dfs).reset_index(drop=True)
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
            test_file = os.path.join(data_dir, f'train_subway{test_year}.csv')
            print(f"ğŸ“Š 20{test_year}ë…„ ê²€ì¦ ë°ì´í„° ë¡œë“œ ì¤‘...")
            test_df = pd.read_csv(test_file, encoding='cp949', nrows=sample_size)
            self.test_data = self._preprocess_data(test_df, test_year)

            print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            print(f"  í›ˆë ¨ ë°ì´í„°: {len(self.train_data):,}ê°œ ({', '.join('20'+y for y in train_years)}ë…„)")
            print(f"  ê²€ì¦ ë°ì´í„°: {len(self.test_data):,}ê°œ (20{test_year}ë…„)")
            return True
        
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _preprocess_data(self, df, year):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df.columns = [col.replace(f'train_subway{year}.', '') for col in df.columns]
        
        # ì‹œê°„ íŠ¹ì„± ìƒì„±
        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')
        df['hour'] = df['datetime'].dt.hour
        df['dayofweek'] = df['datetime'].dt.dayofweek
        df['month'] = df['datetime'].dt.month
        df['day'] = df['datetime'].dt.day
        df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
        
        # ê³„ì ˆ íŠ¹ì„±
        df['season'] = df['month'].map({
            12: 0, 1: 0, 2: 0,  # ê²¨ìš¸
            3: 1, 4: 1, 5: 1,   # ë´„
            6: 2, 7: 2, 8: 2,   # ì—¬ë¦„
            9: 3, 10: 3, 11: 3  # ê°€ì„
        })
        
        # ì¶œí‡´ê·¼ ì‹œê°„ íŠ¹ì„±
        df['is_rush_hour'] = df['hour'].apply(
            lambda x: 1 if x in [7, 8, 9, 18, 19, 20] else 0
        )
        
        # ìˆœí™˜ì  ì‹œê°„ íŠ¹ì„±
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        # ê¸°ìƒ ë°ì´í„° ì „ì²˜ë¦¬
        weather_cols = ['ta', 'ws', 'rn_hr1', 'hm']
        for col in weather_cols:
            if col in df.columns:
                # ì´ìƒì¹˜ ì²˜ë¦¬
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                df[col] = df[col].clip(Q1 - 1.5*IQR, Q3 + 1.5*IQR)
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        df = df.fillna(df.median(numeric_only=True))
        
        return df
    
    def prepare_features(self):
        """íŠ¹ì„± ì¤€ë¹„ (í›ˆë ¨/ê²€ì¦ ë°ì´í„° ì¼ê´€ì„± ë³´ì¥)"""
        print("\níŠ¹ì„± ì¤€ë¹„ ì¤‘...")
        
        # íŠ¹ì„± ì„ íƒ
        feature_cols = [
            'hour', 'dayofweek', 'month', 'day', 'season',
            'is_weekend', 'is_rush_hour',
            'hour_sin', 'hour_cos', 'day_sin', 'day_cos',
            'month_sin', 'month_cos',
            'ta', 'ws', 'rn_hr1', 'hm'
        ]
        
        # ê³µí†µ íŠ¹ì„±ë§Œ ì„ íƒ
        available_features = [col for col in feature_cols 
                            if col in self.train_data.columns and col in self.test_data.columns]
        
        # ì—­ ì¸ì½”ë”© (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)
        le_station = LabelEncoder()
        train_stations = self.train_data['station_name'].unique()
        test_stations = self.test_data['station_name'].unique()
        
        # ê³µí†µ ì—­ë§Œ ì‚¬ìš©
        common_stations = set(train_stations) & set(test_stations)
        print(f"ê³µí†µ ì—­: {len(common_stations)}ê°œ - {', '.join(sorted(common_stations))}")
        
        # ê³µí†µ ì—­ë§Œ í•„í„°ë§
        self.train_data = self.train_data[self.train_data['station_name'].isin(common_stations)]
        self.test_data = self.test_data[self.test_data['station_name'].isin(common_stations)]
        
        # ì—­ ì¸ì½”ë”©
        le_station.fit(sorted(common_stations))
        self.train_data['station_encoded'] = le_station.transform(self.train_data['station_name'])
        self.test_data['station_encoded'] = le_station.transform(self.test_data['station_name'])
        
        available_features.append('station_encoded')
        
        # íŠ¹ì„± ë° íƒ€ê²Ÿ ì¤€ë¹„
        X_train = self.train_data[available_features]
        y_train = self.train_data['congestion']
        X_test = self.test_data[available_features]
        y_test = self.test_data['congestion']
        
        # ê²°ì¸¡ê°’ ì œê±°
        train_mask = ~(X_train.isna().any(axis=1) | y_train.isna())
        test_mask = ~(X_test.isna().any(axis=1) | y_test.isna())
        
        X_train = X_train[train_mask]
        y_train = y_train[train_mask]
        X_test = X_test[test_mask]
        y_test = y_test[test_mask]
        
        print(f"íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ:")
        print(f"  - íŠ¹ì„± ìˆ˜: {len(available_features)}")
        print(f"  - í›ˆë ¨ ìƒ˜í”Œ: {len(X_train):,}ê°œ")
        print(f"  - ê²€ì¦ ìƒ˜í”Œ: {len(X_test):,}ê°œ")
        
        self.feature_names = available_features
        return X_train, y_train, X_test, y_test
    
    def train_and_validate(self, X_train, y_train, X_test, y_test):
        """ëª¨ë¸ í›ˆë ¨ ë° ê²€ì¦"""
        print("\nì‹œê³„ì—´ ê²€ì¦ ì‹œì‘ (2021â†’2022)")
        print("-" * 60)
        
        # ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ëª¨ë¸ ì •ì˜
        models = {
            #'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
            #'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, tree_method='gpu_hist')

        }
        
        results = {}
        
        for name, model in models.items():
            print(f"  {name} í›ˆë ¨ ì¤‘...")
            
            try:
                # ëª¨ë¸ í›ˆë ¨ (2021 ë°ì´í„°)
                if name == 'Linear Regression':
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                
                # 2022 ë°ì´í„°ë¡œ ê²€ì¦
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)
                
                results[name] = {
                    'model': model,
                    'mae': mae,
                    'rmse': rmse,
                    'r2': r2,
                    'predictions': y_pred
                }
                
                print(f"    âœ… {name} ì™„ë£Œ - MAE: {mae:.3f}, RÂ²: {r2:.3f}")
                
            except Exception as e:
                print(f"   {name} ì‹¤íŒ¨: {str(e)}")
        
        self.models = models
        self.results = results
        self.X_test = X_test
        self.y_test = y_test
        
        return results
    
    def analyze_temporal_generalization(self):
        """ì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "="*60)
        print("ì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥ ë¶„ì„")
        print("="*60)
        
        # ì—°ë„ë³„ ë°ì´í„° íŠ¹ì„± ë¹„êµ
        print(f"\nì—°ë„ë³„ ë°ì´í„° íŠ¹ì„± ë¹„êµ:")
        
        train_stats = {
            'í‰ê·  í˜¼ì¡ë„': self.train_data['congestion'].mean(),
            'í˜¼ì¡ë„ í‘œì¤€í¸ì°¨': self.train_data['congestion'].std(),
            'í‰ê·  ì˜¨ë„': self.train_data['ta'].mean(),
            'í‰ê·  ìŠµë„': self.train_data['hm'].mean(),
        }
        
        test_stats = {
            'í‰ê·  í˜¼ì¡ë„': self.test_data['congestion'].mean(),
            'í˜¼ì¡ë„ í‘œì¤€í¸ì°¨': self.test_data['congestion'].std(),
            'í‰ê·  ì˜¨ë„': self.test_data['ta'].mean(),
            'í‰ê·  ìŠµë„': self.test_data['hm'].mean(),
        }
        
        print(f"{'íŠ¹ì„±':<15} {'2021ë…„':<10} {'2022ë…„':<10} {'ì°¨ì´':<10}")
        print("-" * 50)
        for key in train_stats:
            diff = test_stats[key] - train_stats[key]
            print(f"{key:<15} {train_stats[key]:<10.2f} {test_stats[key]:<10.2f} {diff:+7.2f}")
        
        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        print(f"\nëª¨ë¸ë³„ ì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥:")
        print(f"{'ëª¨ë¸ëª…':<20} {'MAE':<10} {'RMSE':<10} {'RÂ²':<10}")
        print("-" * 55)
        
        for name, result in self.results.items():
            print(f"{name:<20} {result['mae']:<10.3f} {result['rmse']:<10.3f} {result['r2']:<10.3f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])
        best_result = self.results[best_model_name]
        
        print(f"\nìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
        print(f"  - MAE: {best_result['mae']:.3f}")
        print(f"  - RÂ²: {best_result['r2']:.3f}")
        
        return best_model_name, best_result
    
    def plot_validation_results(self):
        """ê²€ì¦ ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“Š ê²€ì¦ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ì—°ë„ë³„ í˜¼ì¡ë„ ë¶„í¬ ë¹„êµ
        axes[0, 0].hist(self.train_data['congestion'], bins=50, alpha=0.7, 
                       label='2021ë…„ (í›ˆë ¨)', density=True)
        axes[0, 0].hist(self.test_data['congestion'], bins=50, alpha=0.7, 
                       label='2022ë…„ (ê²€ì¦)', density=True)
        axes[0, 0].set_title('ì—°ë„ë³„ í˜¼ì¡ë„ ë¶„í¬ ë¹„êµ')
        axes[0, 0].set_xlabel('í˜¼ì¡ë„')
        axes[0, 0].set_ylabel('ë°€ë„')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_names = list(self.results.keys())
        mae_scores = [self.results[name]['mae'] for name in model_names]
        r2_scores = [self.results[name]['r2'] for name in model_names]
        
        x_pos = np.arange(len(model_names))
        axes[0, 1].bar(x_pos, mae_scores, alpha=0.7, color='skyblue')
        axes[0, 1].set_title('ëª¨ë¸ë³„ MAE (2022ë…„ ê²€ì¦)')
        axes[0, 1].set_xlabel('ëª¨ë¸')
        axes[0, 1].set_ylabel('MAE')
        axes[0, 1].set_xticks(x_pos)
        axes[0, 1].set_xticklabels(model_names, rotation=45)
        
        # ê°’ í‘œì‹œ
        for i, v in enumerate(mae_scores):
            axes[0, 1].text(i, v + 0.05, f'{v:.3f}', ha='center')
        
        # 3. RÂ² ì ìˆ˜
        axes[0, 2].bar(x_pos, r2_scores, alpha=0.7, color='lightgreen')
        axes[0, 2].set_title('ëª¨ë¸ë³„ RÂ² (2022ë…„ ê²€ì¦)')
        axes[0, 2].set_xlabel('ëª¨ë¸')
        axes[0, 2].set_ylabel('RÂ²')
        axes[0, 2].set_xticks(x_pos)
        axes[0, 2].set_xticklabels(model_names, rotation=45)
        
        for i, v in enumerate(r2_scores):
            axes[0, 2].text(i, v + 0.01, f'{v:.3f}', ha='center')
        
        # 4. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ ì˜ˆì¸¡ vs ì‹¤ì œ
        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])
        best_predictions = self.results[best_model_name]['predictions']
        
        # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°í™”ê°€ ì–´ë ¤ì›€)
        sample_size = min(5000, len(self.y_test))
        sample_indices = np.random.choice(len(self.y_test), sample_size, replace=False)
        
        axes[1, 0].scatter(self.y_test.iloc[sample_indices], best_predictions[sample_indices], 
                          alpha=0.5, s=1)
        axes[1, 0].plot([self.y_test.min(), self.y_test.max()], 
                       [self.y_test.min(), self.y_test.max()], 'r--', lw=2)
        axes[1, 0].set_title(f'{best_model_name} - ì˜ˆì¸¡ vs ì‹¤ì œ')
        axes[1, 0].set_xlabel('ì‹¤ì œê°’ (2022)')
        axes[1, 0].set_ylabel('ì˜ˆì¸¡ê°’')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 5. ì”ì°¨ ë¶„ì„
        residuals = self.y_test.iloc[sample_indices] - best_predictions[sample_indices]
        axes[1, 1].scatter(best_predictions[sample_indices], residuals, alpha=0.5, s=1)
        axes[1, 1].axhline(y=0, color='r', linestyle='--')
        axes[1, 1].set_title('ì”ì°¨ ë¶„ì„')
        axes[1, 1].set_xlabel('ì˜ˆì¸¡ê°’')
        axes[1, 1].set_ylabel('ì”ì°¨')
        axes[1, 1].grid(True, alpha=0.3)
        
        # 6. ì‹œê°„ë³„ ì„±ëŠ¥ ë¶„ì„
        # 2022ë…„ ë°ì´í„°ì— ì˜ˆì¸¡ê°’ ì¶”ê°€
        test_with_pred = self.test_data.copy()
        test_with_pred['predictions'] = best_predictions
        test_with_pred['residuals'] = abs(test_with_pred['congestion'] - test_with_pred['predictions'])
        
        hourly_mae = test_with_pred.groupby('hour')['residuals'].mean()
        axes[1, 2].plot(hourly_mae.index, hourly_mae.values, marker='o', linewidth=2)
        axes[1, 2].set_title('ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ì˜¤ì°¨ (MAE)')
        axes[1, 2].set_xlabel('ì‹œê°„')
        axes[1, 2].set_ylabel('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨')
        axes[1, 2].grid(True, alpha=0.3)
        axes[1, 2].set_xticks(range(0, 24, 2))
        
        plt.tight_layout()
        plt.savefig('../result/time_series_validation.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_insights(self):
        """ì‹œê³„ì—´ ê²€ì¦ ì¸ì‚¬ì´íŠ¸"""
        print("\n" + "="*60)
        print("ì‹œê³„ì—´ ê²€ì¦ ì¸ì‚¬ì´íŠ¸")
        print("="*60)
        
        best_model_name = min(self.results.keys(), key=lambda x: self.results[x]['mae'])
        best_result = self.results[best_model_name]
        
        print(f"\nì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥:")
        print(f"  - ìµœê³  ëª¨ë¸: {best_model_name}")
        print(f"  - 2022ë…„ ì˜ˆì¸¡ MAE: {best_result['mae']:.3f}")
        print(f"  - 2022ë…„ ì˜ˆì¸¡ RÂ²: {best_result['r2']:.3f}")
        
        # ì„±ëŠ¥ í‰ê°€
        if best_result['r2'] > 0.8:
            performance = "ìš°ìˆ˜"
        elif best_result['r2'] > 0.6:
            performance = "ì–‘í˜¸"
        else:
            performance = "ê°œì„  í•„ìš”"
        
        print(f"\nì„±ëŠ¥ í‰ê°€: {performance}")
        
        print(f"\nì‹œê³„ì—´ ëª¨ë¸ë§ ê¶Œì¥ì‚¬í•­:")
        if best_result['r2'] > 0.7:
            print(f"  ëª¨ë¸ì´ ì‹œê°„ì  íŒ¨í„´ì„ ì˜ í•™ìŠµí–ˆìŠµë‹ˆë‹¤")
            print(f"  2022ë…„ ë°ì´í„°ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜")
            print(f"  ì¶”ê°€ ê°œì„ : í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ì•™ìƒë¸”")
        else:
            print(f"  ì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„  í•„ìš”")
            print(f"  ì¶”ì²œ ë°©ë²•: Lag features, ê³„ì ˆì„± ê°•í™”, ì™¸ë¶€ ë°ì´í„° ì¶”ê°€")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ì‹œê³„ì—´ ê²€ì¦ ì‹œì‘: 2021ë…„ í›ˆë ¨ â†’ 2022ë…„ ê²€ì¦")
    print("=" * 60)
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = TimeSeriesValidator()
    
    # 1. ë°ì´í„° ë¡œë“œ
    if not validator.load_data(train_years=['21', '22'], test_year='23', sample_size=5000000):
        return None
    
    # 2. íŠ¹ì„± ì¤€ë¹„
    X_train, y_train, X_test, y_test = validator.prepare_features()
    
    # 3. ëª¨ë¸ í›ˆë ¨ ë° ê²€ì¦
    results = validator.train_and_validate(X_train, y_train, X_test, y_test)
    
    # 4. ì‹œê°„ì  ì¼ë°˜í™” ì„±ëŠ¥ ë¶„ì„
    validator.analyze_temporal_generalization()
    
    # 5. ê²°ê³¼ ì‹œê°í™”
    validator.plot_validation_results()
    
    # 6. ì¸ì‚¬ì´íŠ¸ ìƒì„±
    validator.generate_insights()
    
    print(f"\nì‹œê³„ì—´ ê²€ì¦ ì™„ë ¤")
    print(f"ê²°ê³¼ ì´ë¯¸ì§€: time_series_validation.png")
    
    return validator

if __name__ == "__main__":
    validator = main() 
